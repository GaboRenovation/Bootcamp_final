{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1f0e35",
   "metadata": {},
   "source": [
    "# Superstore Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4460e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "from collections import Counter\n",
    "\n",
    "# Python SQL toolkit and Object Relational Mapper\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func\n",
    "import psycopg2\n",
    "# Database credentials\n",
    "import config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6e13a9",
   "metadata": {},
   "source": [
    "The config file includes the credentials to get access to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d5d71",
   "metadata": {},
   "source": [
    "# Extract data from database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2126d08f",
   "metadata": {},
   "source": [
    "- Set up connection with server where the database is stored (AWS).\n",
    "- Create engine for the connection.\n",
    "- Choose the table that contains the required information for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c73576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection string, user name and password on config.py\n",
    "con_string=f'postgresql+psycopg2://{config.username}:{config.password}@superstoredatabase.c7uct1bmfzis.us-east-2.rds.amazonaws.com:5432/superstoredatabase'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6543cbcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '_instantiate_plugins'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cff44bbd472a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py\u001b[0m in \u001b[0;36mwarned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m                         \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                     )\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.8/site-packages/sqlalchemy/engine/create.py\u001b[0m in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instantiate_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0mentrypoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_entrypoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_instantiate_plugins'"
     ]
    }
   ],
   "source": [
    "# Create engine\n",
    "engine = create_engine(con_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29087288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas read_sql to get table superstore_complete\n",
    "superstore_df = pd.read_sql(\"SELECT * FROM superstore_complete\", engine)\n",
    "superstore_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8bf3d2",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd33d471",
   "metadata": {},
   "source": [
    "- Check for null values.\n",
    "- Look at the data types of the dataframe and transform into the correct data types (ship_date, order_date).\n",
    "- Look at sumary statistics for all the dataframe.\n",
    "- Add columns for the analysis and Machine Learning model (week_day, Month_number, profit_classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "superstore_df[superstore_df.notnull()].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ce464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at general statistics and size\n",
    "print(f'Data size: {superstore_df.shape}')\n",
    "superstore_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a49f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the data types of the df\n",
    "superstore_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify datatypes of Order and Ship Date to datetime\n",
    "\n",
    "superstore_df['order_date']=pd.to_datetime(superstore_df['order_date'])\n",
    "superstore_df['ship_date']=pd.to_datetime(superstore_df['ship_date'])\n",
    "superstore_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e17ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get day of the week from Order Date column (0=monday - 6=Sunday)\n",
    "\n",
    "superstore_df['week_day']=pd.DatetimeIndex(superstore_df['order_date']).dayofweek\n",
    "superstore_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e968cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get month from Order Date column (1=january - 12=December)\n",
    "\n",
    "superstore_df['Month_number']=pd.DatetimeIndex(superstore_df['order_date']).month\n",
    "superstore_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify rows into profitable (1) and non-profitable (0)\n",
    "\n",
    "superstore_df['profit_classification']= np.where(superstore_df['profit']<=0, 0, 1)\n",
    "superstore_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order Dataframe by order date\n",
    "superstore_df=superstore_df.sort_values('order_date',ascending=True)\n",
    "superstore_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f03216",
   "metadata": {},
   "source": [
    "# ***Machine Learning Model - Profitable and not profitable orders***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a74cb6",
   "metadata": {},
   "source": [
    "Using a supervised machine learning model we are going to find out through classification when an order will be profitable or not profitable using as outcome the column **profit_classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c3eee4",
   "metadata": {},
   "source": [
    "# Transform data to fit into Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ef4ff",
   "metadata": {},
   "source": [
    "- Eliminate unnecesary columns.\n",
    "- Encode classification columns with OneHotEncoder.\n",
    "- Choose independent and dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ca1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecesary columns\n",
    "\n",
    "superstore_ML_df=superstore_df.drop(columns=['row_id',\n",
    "                                          'order_id',\n",
    "                                          'customer_id',\n",
    "                                          'customer_name',\n",
    "                                          'postal_code',\n",
    "                                          'product_id',\n",
    "                                          'product_name',\n",
    "                                          'ship_date',\n",
    "                                          'city',\n",
    "                                          'state',\n",
    "                                          'country',\n",
    "                                          'order_date',\n",
    "                                          'sub_category',\n",
    "                                          'market',\n",
    "                                          'profit',\n",
    "                                            'person',\n",
    "                                             'return'                                        \n",
    "                                         ])\n",
    "superstore_ML_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18732f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "superstore_categories = superstore_ML_df.dtypes[superstore_ML_df.dtypes == \"object\"].index.tolist()\n",
    "superstore_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0acc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(superstore_ML_df[superstore_categories]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(superstore_categories)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c9450e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "superstore_ML_df = superstore_ML_df.merge(encode_df,left_index=True, right_index=True)\n",
    "superstore_ML_df = superstore_ML_df.drop(superstore_categories,1)\n",
    "superstore_ML_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a24278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=superstore_ML_df.copy()\n",
    "X=superstore_ML_df.drop(columns=['profit_classification'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829cf23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=superstore_ML_df['profit_classification']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdfb5a1",
   "metadata": {},
   "source": [
    "# Train and test Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c2708f",
   "metadata": {},
   "source": [
    "- Split data into training and test usign the default values, 75% for training and 25 for testing.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=25)\n",
    "\n",
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting Standard Scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5276e0e2",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72020a5",
   "metadata": {},
   "source": [
    "- Fit chosen algoithm (logistic regression) for classification\n",
    "- Extract accuracy scores and confusion matrix to determine if the model is usefull or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8da918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=100,\n",
    "                                random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f6d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd65406",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual Not-Profitable\", \"Profitable\"], columns=[\"Predicted Not-Profitable\", \"Predicted Profitable\"])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dee264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy score.\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b9a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e455fd5b",
   "metadata": {},
   "source": [
    "# ***Machine Learning Model - Determine if an order will be returned***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebcbdbc",
   "metadata": {},
   "source": [
    "Using a supervised machine learning model we are going to find out through classification if an order could be returned using as outcome the column **return_Yes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15de3f3",
   "metadata": {},
   "source": [
    "# Transform data to fit into Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2ad6b4",
   "metadata": {},
   "source": [
    "- Eliminate unnecesary columns.\n",
    "- Encode classification columns with OneHotEncoder.\n",
    "- Choose independent and dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77519b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecesary columns\n",
    "superstore_ML_GD=superstore_df.drop(columns=['row_id',\n",
    "                                              'order_id',\n",
    "                                              'profit_classification',\n",
    "                                                 'profit',\n",
    "                                                 'week_day',\n",
    "                                                 'Month_number',\n",
    "                                                 'market',\n",
    "                                             'order_date',\n",
    "                                             'ship_date',\n",
    "                                             'customer_id',\n",
    "                                             'customer_name',\n",
    "                                             'city',\n",
    "                                             'state',\n",
    "                                             'postal_code',\n",
    "                                             'product_id',\n",
    "                                             'person',\n",
    "                                             'country',\n",
    "                                             'product_name',\n",
    "                                             'sub_category',\n",
    "                                             'sales'\n",
    "                                              ])\n",
    "superstore_ML_GD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "superstore_categories = superstore_ML_GD.dtypes[superstore_ML_GD.dtypes == \"object\"].index.tolist()\n",
    "superstore_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ef718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(superstore_ML_GD[superstore_categories]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(superstore_categories)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "superstore_ML_GD = superstore_ML_GD.merge(encode_df,left_index=True, right_index=True)\n",
    "superstore_ML_GD = superstore_ML_GD.drop(superstore_categories,1)\n",
    "superstore_ML_GD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d627ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set\n",
    "X = superstore_ML_GD.copy()\n",
    "X = X.drop(columns=[\"return_Yes\",\"return_None\"],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b6e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target vector\n",
    "y = superstore_ML_GD[\"return_Yes\"].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8bf7d",
   "metadata": {},
   "source": [
    "# Train and test Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38c9d2",
   "metadata": {},
   "source": [
    "- Split data into training and test usign the default values, 75% for training and 25 for testing.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e9315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=25)\n",
    "\n",
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting Standard Scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37632a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the size of the sample\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77b17b6",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daee31d",
   "metadata": {},
   "source": [
    " - Apply SMOTE to balance the training set as 5% = 1 and 95%=No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee45b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled,y_resampled=SMOTE(random_state=25,sampling_strategy='auto').fit_resample(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81808e8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c751d2f6",
   "metadata": {},
   "source": [
    "# Balanced Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b80d3",
   "metadata": {},
   "source": [
    "- Fit chosen algoithm (Random Forest) for classification.\n",
    "- Extract accuracy scores and confusion matrix to determine if the model is usefull or not.\n",
    "- Get feature importances to determine wigh variables influence the outcome the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e713860",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "brf=BalancedRandomForestClassifier(n_estimators=500,random_state=25)\n",
    "brf_model=brf.fit(X_resampled,y_resampled)\n",
    "brf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2badff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = brf_model.predict(X_test_scaled)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f62b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual No-return\", \"Actual Return\"],\n",
    "    columns=[\"Predicted No-return\", \"Predicted Return\"]\n",
    ")\n",
    "\n",
    "# Displaying results\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b3dc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "importances=brf_model.feature_importances_\n",
    "feat_imp=sorted(zip(importances,X.columns),reverse=True)\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0223c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sorted(zip(X.columns, importances), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(10,20)\n",
    "plt.margins(y=0.001)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
